{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yVQ3kgnwpmPjsPXvJrF7jEFoN-tt9UZf",
      "authorship_tag": "ABX9TyMRhMc4CcYRqMH9K4cwIIYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OliviaHelena10/skincare_recommendations/blob/main/Colab_Predict_Skins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "sBLy4WFzsO4c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "J3i5tQF_rtOb"
      },
      "outputs": [],
      "source": [
        "# Basic DS libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Will help to list our files\n",
        "from glob import glob\n",
        "import pathlib\n",
        "import PIL\n",
        "\n",
        "# Will help us with the images\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Organising our Data"
      ],
      "metadata": {
        "id": "2XAB26IysO1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Getting our data path:"
      ],
      "metadata": {
        "id": "sZjsn0lvDkGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are accessing our data from google drive\n",
        "path_train = '/content/drive/MyDrive/skin_search/train'\n",
        "path_test = '/content/drive/MyDrive/skin_search/test'\n",
        "path_validation = '/content/drive/MyDrive/skin_search/valid'"
      ],
      "metadata": {
        "id": "Ka95csUGsX9-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the paths in variables:"
      ],
      "metadata": {
        "id": "BZmIXKBLDoDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = pathlib.Path(path_train)\n",
        "test_dir = pathlib.Path(path_test)\n",
        "validation_dir = pathlib.Path(path_validation)"
      ],
      "metadata": {
        "id": "jB4qZW3TDnSV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the categories:"
      ],
      "metadata": {
        "id": "qHOxwRa3Dv5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/skin_search/train'\n",
        "data_dir = pathlib.Path(path)\n",
        "\n",
        "\n",
        "# Iterating through the train subfolders and getting their names just in case\n",
        "train_subfolders = [f.name for f in data_dir.iterdir() if f.is_dir()]\n",
        "print(f'train: {train_subfolders}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QbHToRGsfOj",
        "outputId": "9389fda6-3442-46e9-f5e5-ecb36cef218d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ['dry', 'normal', 'oily']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for subfolder in train_subfolders:\n",
        "  path =  train_dir / subfolder\n",
        "  images = list(path.glob('*.JPG'))\n",
        "  print(f'{subfolder}: {len(images)} imagens')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7foBzShpIPoZ",
        "outputId": "43aa5f9d-f637-4664-9cc3-2c2825fca6df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dry: 0 imagens\n",
            "normal: 0 imagens\n",
            "oily: 0 imagens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking our Datas\n",
        "\n",
        "for subfolder in train_subfolders:                # iterates through the subfolders: dry, normal and oily\n",
        "  path =  train_dir / subfolder                   # gets the path of each image\n",
        "  images = list(path.glob('*.jpg'))               # gets the images of each subfolder\n",
        "  print(f'\\n{subfolder}: {len(images)} imagens')  # prints the number of data in each subfolder\n",
        "\n",
        "  if images:\n",
        "    img = PIL.Image.open(str(images[0]))          # opens the first image in the list\n",
        "    img_array = np.array(img)                     # converts the image to a numpy array\n",
        "    print(f'dimensões da primeira imagem em {subfolder} : {img_array.shape}\\n') # gets our image dimensions\n",
        "  print(\"------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uLKteWgsic0",
        "outputId": "51d0adb0-bfe5-41ee-d9b9-8312b472431a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "dry: 662 imagens\n",
            "dimensões da primeira imagem em dry : (640, 640, 3)\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "normal: 1114 imagens\n",
            "dimensões da primeira imagem em normal : (640, 640, 3)\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "oily: 1015 imagens\n",
            "dimensões da primeira imagem em oily : (640, 640, 3)\n",
            "\n",
            "------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image preprocessing for model training"
      ],
      "metadata": {
        "id": "n-wIEtCKsqpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Variables:"
      ],
      "metadata": {
        "id": "ebOipMwILfD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We must maintain tha same proportions of the images width and height\n",
        "image_width = 640\n",
        "image_height = 640\n",
        "\n",
        "\n",
        "# Images always have 3 color dimensions RGB pr BGR        ( R for Red  -  G for Green  -  B for Blue )\n",
        "image_color_channel = 3\n",
        "image_color_channel_size = 255\n",
        "image_size = (image_width, image_height)\n",
        "img_shape = image_size + (image_color_channel,)\n",
        "\n",
        "batch_size = 128            # number of features that I will bring at a time from my dataset\n",
        "epocas = 32                 # number of times that I will iterate trought my dataset\n",
        "learning_rate = 0.0001\n",
        "\n",
        "class_names = ['dry', 'normal', 'oily']"
      ],
      "metadata": {
        "id": "V8sXYGcSsrpA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separating train, test and validation data"
      ],
      "metadata": {
        "id": "zIBuTogDLjKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    seed = 568,         # this will get random weights for the transformations\n",
        "    image_size = (image_height,image_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOH_6U4kst3V",
        "outputId": "fc86bff3-1751-49e3-a29d-2d101d919a1a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2792 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    seed = 568,         # this will get random weights for the transformations\n",
        "    image_size = (image_height,image_width),\n",
        "    batch_size = batch_size\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVCSehNiswVx",
        "outputId": "a1a71e37-023c-4d48-f245-371d5809c09e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 134 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation = tf.keras.utils.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    seed = 568,         # this will get random weights for the transformations\n",
        "    image_size = (image_height,image_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "selY2YXEsyR6",
        "outputId": "938d1a39-4684-4e3e-888e-05559823c158"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 262 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Machine Learning Supervised Learning model - type Image Classification"
      ],
      "metadata": {
        "id": "cBNzudegtPo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # Input:\n",
        "    tf.keras.layers.Input(shape=(640, 640,  3)),                                # This are the dimensions from our input data\n",
        "\n",
        "    # Reescaling Layers\n",
        "    tf.keras.layers.Rescaling(1./255),                                          # Normalizing our data by reescaling the pixels\n",
        "\n",
        "    # Padding Layers\n",
        "    tf.keras.layers.Flatten(),                                                  # Flattening our data to 1 dimension\n",
        "\n",
        "    # Hidden Layers:\n",
        "    tf.keras.layers.Dense(128,activation=tf.nn.relu),                           # Dense Layer will do the \"math\" for getting our results\n",
        "\n",
        "    # Output:\n",
        "    tf.keras.layers.Dense(3, activation=tf.nn.softmax)                          # Softmax activation is used for cathegorical data and 3 are the dimensions in our dataset\n",
        "])"
      ],
      "metadata": {
        "id": "CWmC_qe4tK6A"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "EhvJj7OqtTQG",
        "outputId": "d88724cf-456a-4644-9edb-f1d2d2d078d8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rescaling_1 (\u001b[38;5;33mRescaling\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m, \u001b[38;5;34m640\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1228800\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │     \u001b[38;5;34m157,286,528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rescaling_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1228800</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │     <span style=\"color: #00af00; text-decoration-color: #00af00\">157,286,528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m157,286,915\u001b[0m (600.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,286,915</span> (600.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m157,286,915\u001b[0m (600.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,286,915</span> (600.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),           # Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments\n",
        "              loss='sparse_categorical_crossentropy',           # Will show the lesses of our training\n",
        "              metrics=['accuracy'])                             # List of metrics to be evaluated by the model during training and testing."
      ],
      "metadata": {
        "id": "VgKeHZz8tVdj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = 32\n",
        "\n",
        "history = model.fit(\n",
        "    train,\n",
        "    validation_data = validation,\n",
        "    epochs = epocas # qtd de iterações q o algoritmo irá fazer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjIorLsHtYlO",
        "outputId": "a6f10f00-abe9-4c1e-d691-d4d56dfd8966"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 797ms/step - accuracy: 0.3802 - loss: 87.2206 - val_accuracy: 0.3435 - val_loss: 26.9111\n",
            "Epoch 2/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 654ms/step - accuracy: 0.3820 - loss: 43.3286 - val_accuracy: 0.4237 - val_loss: 82.4885\n",
            "Epoch 3/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 616ms/step - accuracy: 0.3822 - loss: 59.9828 - val_accuracy: 0.3130 - val_loss: 22.9077\n",
            "Epoch 4/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 641ms/step - accuracy: 0.4301 - loss: 27.3718 - val_accuracy: 0.4122 - val_loss: 33.8740\n",
            "Epoch 5/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 624ms/step - accuracy: 0.4183 - loss: 41.1149 - val_accuracy: 0.4122 - val_loss: 34.5378\n",
            "Epoch 6/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 613ms/step - accuracy: 0.4299 - loss: 48.2581 - val_accuracy: 0.4046 - val_loss: 23.5929\n",
            "Epoch 7/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 638ms/step - accuracy: 0.5046 - loss: 16.3679 - val_accuracy: 0.4160 - val_loss: 48.7826\n",
            "Epoch 8/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 666ms/step - accuracy: 0.4296 - loss: 30.0517 - val_accuracy: 0.2939 - val_loss: 36.1109\n",
            "Epoch 9/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 618ms/step - accuracy: 0.4332 - loss: 21.8254 - val_accuracy: 0.3740 - val_loss: 23.3292\n",
            "Epoch 10/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 619ms/step - accuracy: 0.5093 - loss: 15.6731 - val_accuracy: 0.4084 - val_loss: 23.8261\n",
            "Epoch 11/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 615ms/step - accuracy: 0.4917 - loss: 24.7388 - val_accuracy: 0.4237 - val_loss: 53.4655\n",
            "Epoch 12/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 620ms/step - accuracy: 0.4263 - loss: 44.0880 - val_accuracy: 0.3969 - val_loss: 21.7138\n",
            "Epoch 13/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 623ms/step - accuracy: 0.5311 - loss: 13.5664 - val_accuracy: 0.4046 - val_loss: 18.8056\n",
            "Epoch 14/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 607ms/step - accuracy: 0.5777 - loss: 9.3647 - val_accuracy: 0.3206 - val_loss: 15.6871\n",
            "Epoch 15/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 651ms/step - accuracy: 0.5513 - loss: 9.3306 - val_accuracy: 0.3511 - val_loss: 14.8546\n",
            "Epoch 16/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 621ms/step - accuracy: 0.5441 - loss: 9.2046 - val_accuracy: 0.3473 - val_loss: 11.9159\n",
            "Epoch 17/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 630ms/step - accuracy: 0.5789 - loss: 8.7498 - val_accuracy: 0.2748 - val_loss: 28.0377\n",
            "Epoch 18/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 702ms/step - accuracy: 0.5588 - loss: 10.2824 - val_accuracy: 0.2824 - val_loss: 20.7623\n",
            "Epoch 19/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 678ms/step - accuracy: 0.5436 - loss: 10.4818 - val_accuracy: 0.3321 - val_loss: 12.6024\n",
            "Epoch 20/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 688ms/step - accuracy: 0.5550 - loss: 10.3295 - val_accuracy: 0.4275 - val_loss: 28.3533\n",
            "Epoch 21/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 750ms/step - accuracy: 0.4590 - loss: 24.0020 - val_accuracy: 0.3511 - val_loss: 15.7085\n",
            "Epoch 22/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 664ms/step - accuracy: 0.6452 - loss: 4.5230 - val_accuracy: 0.4198 - val_loss: 12.1277\n",
            "Epoch 23/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 746ms/step - accuracy: 0.6100 - loss: 6.8536 - val_accuracy: 0.4237 - val_loss: 20.7114\n",
            "Epoch 24/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 654ms/step - accuracy: 0.5936 - loss: 6.9186 - val_accuracy: 0.3053 - val_loss: 10.9995\n",
            "Epoch 25/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 630ms/step - accuracy: 0.7343 - loss: 2.5268 - val_accuracy: 0.3931 - val_loss: 13.8887\n",
            "Epoch 26/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 687ms/step - accuracy: 0.6446 - loss: 5.5402 - val_accuracy: 0.3092 - val_loss: 14.8406\n",
            "Epoch 27/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 681ms/step - accuracy: 0.5623 - loss: 10.7622 - val_accuracy: 0.2824 - val_loss: 16.2636\n",
            "Epoch 28/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 678ms/step - accuracy: 0.6156 - loss: 7.2448 - val_accuracy: 0.4046 - val_loss: 17.4805\n",
            "Epoch 29/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 671ms/step - accuracy: 0.6098 - loss: 6.6094 - val_accuracy: 0.3092 - val_loss: 15.0940\n",
            "Epoch 30/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 645ms/step - accuracy: 0.6373 - loss: 5.8346 - val_accuracy: 0.4008 - val_loss: 9.4322\n",
            "Epoch 31/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 737ms/step - accuracy: 0.8093 - loss: 1.4904 - val_accuracy: 0.3130 - val_loss: 12.5029\n",
            "Epoch 32/32\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 704ms/step - accuracy: 0.6492 - loss: 4.7840 - val_accuracy: 0.2977 - val_loss: 12.6259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aECzutvA8NmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diOLG_PXGArt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FAZwH_2GFOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}